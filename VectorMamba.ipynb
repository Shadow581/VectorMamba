{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b58dba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, StepLR, ReduceLROnPlateau\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from timm.models.layers import DropPath\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.neighbors import KDTree\n",
    "# from mmcv.ops.group_points import knn, grouping_operation   # knn: k近邻算法   grouping_operation: 使用索引获取特征数据\n",
    "# from mmcv.ops import gather_points, furthest_point_sample, three_nn, three_interpolate # gather_points: 使用索引获取坐标数据   furthest_point_sample: 最远点采样\n",
    "from mmcv.ops import three_nn, three_interpolate \n",
    "from knn_cuda import KNN\n",
    "from pointnet2_ops import pointnet2_utils\n",
    "from glob import glob\n",
    "import h5py\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "import random\n",
    "# import matplotlib.pyplot as plt\n",
    "# import laspy\n",
    "import pickle\n",
    "from thop import profile   # 计算模型参数量和FLOPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d69514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f35bae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bda7e29",
   "metadata": {},
   "source": [
    "### DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5fcc77",
   "metadata": {},
   "source": [
    "#### S3DIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c74e1a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class S3DISDataset(Dataset):\n",
    "    '''\n",
    "    def __init__(self, root=\"./data/S3DIS\", num_point=40960, sub_grid_size=0.04, split=\"train\", \n",
    "                 test_area=5, transform=None, num_layers=4, subsample_ratio=[4, 4, 4, 2], k=16):\n",
    "                 \n",
    "    return:\n",
    "        x, neighbor_index, subsample_index, upsample_index, feature, label\n",
    "     #  x: [num_point, 3]   neighbor_index: [num_point, k]   subsample_index: [num_point//stride, k]  upsample_index: [num_point, 1]\n",
    "     #  feature: [num_point, 4]   label: [num_point,]\n",
    "    '''\n",
    "    def __init__(self, root=\"./data/S3DIS\", num_point=40960, sub_grid_size=0.04, split=\"train\", \n",
    "                 test_area=5, transform=None, num_layers=4, subsample_ratio=[4, 4, 4, 2], k=16):\n",
    "        '''\n",
    "        sub_grid_size: 以sub_grid_size m³为一个网格，在内随机选择一个点，代表该网格\n",
    "        num_layers: 深度神经网络Encoder层的数目\n",
    "        subsample_ratio: 下采样点数比例\n",
    "        k: k近邻\n",
    "        '''\n",
    "        \n",
    "        self.root = root\n",
    "        self.num_point = num_point   # 所需采样的点数\n",
    "        self.sub_grid_size = sub_grid_size\n",
    "        self.split = split\n",
    "        self.transform = transform     # 数据增强\n",
    "        self.num_layers = num_layers   # Encoder层的数目\n",
    "        self.subsample_ratio = subsample_ratio\n",
    "        self.k = k   # k近邻\n",
    "\n",
    "        self.original_path = root+\"/\"+\"original\"\n",
    "        self.tree_path = root+\"/\"+\"sub_grid_sample\"\n",
    "\n",
    "        self.test_proj = []\n",
    "        self.test_proj_label = []\n",
    "        \n",
    "        self.trees = []\n",
    "        self.colors = []\n",
    "        self.labels = []\n",
    "        \n",
    "        self.possibility = []\n",
    "        self.min_possibility = []\n",
    "        \n",
    "        original_files = [os.path.basename(file) for file in glob(self.original_path+\"/*.h5\")]     # ['Area_1_conferenceRoom_1.h5', 'Area_1_conferenceRoom_2.h5', ..., 'Area_6_pantry_1.h5']\n",
    "        if split==\"train\":\n",
    "            original_files = [file for file in original_files if int(file.split(\"_\")[1]) != test_area]\n",
    "        else:\n",
    "            original_files = [file for file in original_files if int(file.split(\"_\")[1]) == test_area]\n",
    "        \n",
    "        for original_file in original_files:\n",
    "            filename = original_file.split(\".\")[0]   # 'Area_1_conferenceRoom_1'\n",
    "            \n",
    "            # Read sub-sampled point cloud data\n",
    "            f = h5py.File(self.tree_path+\"/\"+filename+\".h5\", \"r\")\n",
    "            sub_points = np.array(f[\"data\"])     # [S, 6]  XYZRGB\n",
    "            sub_labels = np.array(f[\"label\"])    # [S,]    L\n",
    "            f.close()\n",
    "            \n",
    "            # Read search tree data\n",
    "            with open(self.tree_path+\"/\"+filename+\"_KDTree.pkl\", \"rb\") as f:\n",
    "                search_tree = pickle.load(f)\n",
    "            \n",
    "            self.trees.append(search_tree)  # 由sub-sample数据生成的search_tree，search_tree.data获取sub-sample数据\n",
    "            self.colors.append(sub_points[:, 3:6])   # [S, 3]\n",
    "            self.labels.append(sub_labels)   # [S,]\n",
    "            \n",
    "            if split!=\"train\":   # Test\n",
    "                with open(self.tree_path+\"/\"+filename+\"_proj.pkl\", \"rb\") as f:\n",
    "                    proj_index, proj_labels = pickle.load(f)   # [N,]  [N,]\n",
    "                self.test_proj.append(proj_index)\n",
    "                self.test_proj_label.append(proj_labels)\n",
    "            \n",
    "        for color in self.colors:\n",
    "            possi = np.random.rand(color.shape[0]) * 1e-3   # [S,]  range:[0, 0.001)\n",
    "            self.possibility.append(possi)   # 对每个点云文件都存储 [S,] 随机数\n",
    "            self.min_possibility.append(min(possi))   # 对每个点云文件都存储 1 个随机数\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # 根据 min_possibility 选取点云\n",
    "        pc_index = np.argmin(self.min_possibility)\n",
    "        # 根据 pc_index 在possibility内 选取 一个点\n",
    "        p_index = np.argmin(self.possibility[pc_index])\n",
    "        \n",
    "        # 根据 pc_index 获取 sub-sample 的点云坐标数据\n",
    "        points = np.array(self.trees[pc_index].data)   # [S, 3]\n",
    "        # 根据 p_index 获取 sub-sample 的某个点坐标数据\n",
    "        center_point = points[p_index, :].reshape(1, -1)   # [1, 3]\n",
    "        \n",
    "        # 给 center_point 添加噪声\n",
    "        noise = np.random.normal(scale=0.35, size=center_point.shape)   # [1, 3]\n",
    "        pick_point = center_point + noise   # [1, 3]\n",
    "        \n",
    "        # 检查 points 的点数是符合 num_point \n",
    "        if points.shape[0] < self.num_point:   # 下采样点数 < num_point\n",
    "            query_index = self.trees[pc_index].query(pick_point, k=points.shape[0])[1][0].astype(np.int32)  # [points.shape[0],]\n",
    "            supplement_index = np.random.choice(query_index, self.num_point-points.shape[0])\n",
    "            query_index = np.concatenate([query_index, supplement_index])   # [num_point,]\n",
    "        else:\n",
    "            query_index = self.trees[pc_index].query(pick_point, k=self.num_point)[1][0].astype(np.int32)   # [num_point,]\n",
    "        \n",
    "        # 打乱 query_index\n",
    "        shuffle_index = np.arange(len(query_index))\n",
    "        np.random.shuffle(shuffle_index)\n",
    "        query_index = query_index[shuffle_index]\n",
    "        \n",
    "        # 根据 query_index 获取相应的坐标数据、颜色数据以及标签值\n",
    "        query_xyz = points[query_index]   # [num_point, 3]\n",
    "        query_height = query_xyz[:, -1:]  # [num_point, 1]  高度特征信息\n",
    "        query_xyz = query_xyz - pick_point   # [S', 3]\n",
    "        query_color = self.colors[pc_index][query_index]   # [num_point, 3]\n",
    "        query_label = self.labels[pc_index][query_index]   # [num_point,]\n",
    "        \n",
    "        # 到此为止，进行了以下步骤：\n",
    "        # 1、首先，随机选取了一个点云\n",
    "        # 2、在该点云内，随机选取一个点\n",
    "        # 3、以该点为中心检索出距离其最近的k个点，获取对应索引\n",
    "        # 4、根据索引，获取坐标数据、颜色数据以及标签值，并且将索引点的坐标相对化。\n",
    "        \n",
    "        # 根据邻近点与中心点的距离，更新 possibility 数据（距离越近，增加越多。增加范围：[0, 1]）\n",
    "        dists = np.sum(query_xyz**2, axis=-1)   # [num_point,]\n",
    "        delta = (1 - dists/max(dists))**2\n",
    "        self.possibility[pc_index][query_index] += delta\n",
    "        self.min_possibility[pc_index] = min(self.possibility[pc_index])\n",
    "        \n",
    "        # ============================================================================================================\n",
    "        # 数据增强\n",
    "        if self.transform:\n",
    "            query_xyz, query_color, query_label = self.transform(query_xyz, query_color, query_label)\n",
    "        # ============================================================================================================\n",
    "        \n",
    "        query_xyz = query_xyz.astype(np.float32)\n",
    "        feature = np.concatenate([query_xyz, query_color, query_height], axis=-1).astype(np.float32)   # [num_point, 4]\n",
    "        label = query_label.astype(np.int32)\n",
    "            \n",
    "        return query_xyz, feature, label   # [N, 3]  [N, 7]  [N,]\n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.split==\"train\":\n",
    "            return len(self.trees) * 240\n",
    "        else:\n",
    "            return len(self.trees) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f8e082",
   "metadata": {},
   "source": [
    "### 网络结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e29d8c0",
   "metadata": {},
   "source": [
    "#### FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bd972bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fps(points, number):\n",
    "    '''\n",
    "    Args:\n",
    "        points: [B, N, 3]\n",
    "        number: subsample point number\n",
    "    return:\n",
    "        fps_idx\n",
    "    '''\n",
    "    fps_idx = pointnet2_utils.furthest_point_sample(points, number)\n",
    "    # fps_data = pointnet2_utils.gather_operation(data.transpose(1, 2).contiguous(), fps_idx).transpose(1, 2).contiguous()\n",
    "    return fps_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4349dc",
   "metadata": {},
   "source": [
    "#### index_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22b6bb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_points(data, index):\n",
    "    '''\n",
    "    获取索引点的坐标或特征\n",
    "    \n",
    "    data：[B, C, N]\n",
    "    index：[B, S, K]\n",
    "    \n",
    "    return；\n",
    "        new_data    # [B, C, S, K]\n",
    "    '''\n",
    "    data = data.permute(0, 2, 1)   # [B, N, C]\n",
    "    \n",
    "    device = data.device\n",
    "    \n",
    "    B = data.shape[0]\n",
    "    \n",
    "    index = index.long()\n",
    "    \n",
    "    view_shape = list(index.shape)    # [B, S]\n",
    "    view_shape[1:] = [1] * (len(view_shape) - 1)    # 变为 [B, 1]     后续需要使用  .view().repeat()\n",
    "    repeat_shape = list(index.shape)  # [B, S]\n",
    "    repeat_shape[0] = 1         # [1, S]\n",
    "    \n",
    "    batch_index = torch.arange(0, B, dtype=torch.long).view(view_shape).repeat(repeat_shape).to(device)   # [B, S]\n",
    "    \n",
    "    new_data = data[batch_index, index]\n",
    "    \n",
    "    return new_data.permute(0, 3, 1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bbe4f8",
   "metadata": {},
   "source": [
    "#### LRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5f293b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LPR(x, index):   # [B, 3, N]\n",
    "    '''\n",
    "    输入:\n",
    "        x: [B, 3, N]\n",
    "        index: [B, N, k]\n",
    "    返回:\n",
    "        knn_x, relative_x, local_rep, exp_x, ratio_volume   # [B, 3, N, k]  [B, 3, N, k]   [B, 3, N, k]  [B, 1, N, k]  [B, N]\n",
    "    '''\n",
    "    B, _, N = x.shape\n",
    "    k = index.shape[-1]\n",
    "\n",
    "    knn_x = index_points(x, index)   # [B, 3, N, k]\n",
    "    central_x = x.unsqueeze(-1).repeat(1, 1, 1, k)   # [B, 3, N, k]\n",
    "\n",
    "    relative_x = central_x - knn_x   # [B, 3, N, k]\n",
    "\n",
    "    # 相对点的 alpha 和 beta\n",
    "    alpha = torch.atan2(relative_x[:, 1, :, :], relative_x[:, 0, :, :]).reshape(B, 1, N, k)   # [B, 1, N, k]\n",
    "    xy_dist = torch.sqrt(torch.sum(torch.square(relative_x[:, :2, :, :]), dim=1)).reshape(B, 1, N, k)   # [B, 1, N, k]\n",
    "    beta = torch.atan2(relative_x[:, 2:, :, :], xy_dist).reshape(B, 1, N, k)   # [B, 1, N, k]\n",
    "    relative_dist = torch.sqrt(torch.sum(torch.square(relative_x), dim=1)).reshape(B, 1, N, k)   # [B, 1, N, k]\n",
    "\n",
    "    exp_x = torch.exp(-relative_dist)   # [B, 1, N, k]\n",
    "    local_volume = torch.pow(torch.max(relative_dist.squeeze(1), dim=-1)[0], 3)   # [B, N]  每个neighbor的体积\n",
    "\n",
    "    # 质心点的 alpha 和 beta\n",
    "    barycentrer_x = torch.mean(knn_x, dim=-1)   # [B, 3, N]  质心\n",
    "    direction_relative = x - barycentrer_x   # [B, 3, N]\n",
    "    direction_relative = direction_relative.unsqueeze(-1).repeat(1, 1, 1, k)   # [B, 3, N, k]\n",
    "    barycentrer_alpha = torch.atan2(direction_relative[:, 1, :, :], direction_relative[:, 0, :, :]).reshape(B, 1, N, k)   # [B, 1, N, k]\n",
    "    xy_dist = torch.sqrt(torch.sum(torch.square(direction_relative[:, :2, :, :]), dim=1)).reshape(B, 1, N, k)   # [B, 1, N, k]\n",
    "    barycentrer_beta = torch.atan2(direction_relative[:, 2:, :, :], xy_dist).reshape(B, 1, N, k)   # [B, 1, N, k]\n",
    "\n",
    "    angle = torch.cat([alpha-barycentrer_alpha, beta-barycentrer_beta], dim=1)   # [B, 2, N, k]\n",
    "\n",
    "    local_rep = torch.cat([relative_dist, angle], dim=1)   # [B, 3, N, k]\n",
    "\n",
    "    global_dist = torch.sqrt(torch.sum(torch.square(x), dim=1))   # [B, N]\n",
    "    global_volume = torch.pow(torch.max(global_dist, dim=-1, keepdim=True)[0], 3)   # [B, 1]\n",
    "\n",
    "    ratio_volume = local_volume / global_volume   # [B, N]\n",
    "\n",
    "    return knn_x, relative_x, local_rep, exp_x, ratio_volume   # [B, 3, N, k]  [B, 3, N, k]   [B, 3, N, k]  [B, 1, N, k]  [B, N]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f946ed07",
   "metadata": {},
   "source": [
    "#### FlaResMLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37c1e81b-735a-40cb-9194-14d8a3855815",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvResMLP(nn.Module):\n",
    "    '''\n",
    "    def __init__(self, input_channel):\n",
    "    \n",
    "    def forward(self, x, neighbor_index, feature):   # [B, 3, N]  [B, N, k]  [B, C, N]\n",
    "    \n",
    "    返回:\n",
    "        feature    # [B, C, N]\n",
    "    '''\n",
    "    def __init__(self, input_channel):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_channel = input_channel\n",
    "        \n",
    "        self.mlpf = nn.Sequential(\n",
    "                        nn.Conv1d(input_channel, (input_channel//3)*3, 1, bias=False),\n",
    "                        nn.BatchNorm1d((input_channel//3)*3),\n",
    "                        nn.LeakyReLU(0.2, True)\n",
    "                    )\n",
    "        \n",
    "        self.mlp1 = nn.Sequential(\n",
    "                       nn.Conv1d((input_channel//3)*3, 4*input_channel, 1, bias=False),\n",
    "                       nn.BatchNorm1d(4*input_channel),\n",
    "                       nn.ReLU(True)\n",
    "                    )\n",
    "        \n",
    "        self.mlp2 = nn.Sequential(\n",
    "                       nn.Conv1d(4*input_channel, input_channel, 1, bias=False),\n",
    "                       nn.BatchNorm1d(input_channel),\n",
    "                    )\n",
    "    \n",
    "    def forward(self, relative_x, x_encoding, neighbor_index, feature):   # [B, 3, N, k]  [B, C, N, k]  [B, N, k]  [B, C, N]\n",
    "        identity = feature\n",
    "\n",
    "        feature = self.mlpf(feature)   # [B, C, N]\n",
    "        knn_feature = index_points(feature, neighbor_index)   # [B, C, N, k]\n",
    "        feature = x_encoding + knn_feature   # [B, C, N, k]\n",
    "        \n",
    "        B, C, N, k = feature.shape\n",
    "        \n",
    "        x_en = relative_x.unsqueeze(2).repeat(1, 1, self.input_channel//3, 1, 1).reshape(B, C, N, k)\n",
    "        feature = x_en * feature   # [B, C, N, k]\n",
    "        \n",
    "        feature = torch.max(feature, dim=-1)[0]   # [B, C, N]\n",
    "        \n",
    "        feature = self.mlp2(self.mlp1(feature))   # [B, C, N]\n",
    "        \n",
    "        # residual\n",
    "        feature =  F.relu(feature+identity, inplace=True)   # [B, C, N]\n",
    "        \n",
    "        return feature    # [B, C, N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be83990-d0bb-4e3a-aa3a-838b86bf91ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0925b216-1e68-4d9e-9a8d-5e4d5abe4af2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fcf0dc-3a37-4029-bce1-9d41a5eaccbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c8a9343",
   "metadata": {},
   "source": [
    "#### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c4b3dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    '''\n",
    "    def __init__(self, input_channel, output_channel, k, stride, inverse_num):\n",
    "    \n",
    "    def forward(self, x, feature):   # [B, 3, N]  [B, C, N]\n",
    "    \n",
    "    return:\n",
    "        feature, sub_x, neighbor_index   # [B, out, S]  [B, 3, S]\n",
    "    '''\n",
    "    def __init__(self, input_channel, output_channel, k, stride, inverse_num):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.k = k\n",
    "        self.stride = stride\n",
    "\n",
    "        self.mlp_f1 = nn.Sequential(\n",
    "                        nn.Conv2d(input_channel, 1, 1),\n",
    "                    )\n",
    "        \n",
    "        self.mlp_f2 = nn.Sequential(\n",
    "                        nn.Conv2d(input_channel, output_channel//2, 1),\n",
    "                        nn.BatchNorm2d(output_channel//2),\n",
    "                        nn.ReLU(True)\n",
    "                    )\n",
    "\n",
    "        self.Rw = nn.Parameter(torch.randn(output_channel//2, 2))\n",
    "        \n",
    "        self.mlp1 = nn.Sequential(\n",
    "                        nn.Conv2d(input_channel+9, output_channel, 1),\n",
    "                        nn.BatchNorm2d(output_channel),\n",
    "                        nn.ReLU(True)\n",
    "                    )\n",
    "        \n",
    "        self.mlp2 = nn.Sequential(\n",
    "                        nn.Conv1d(output_channel, output_channel, 1),\n",
    "                        nn.BatchNorm1d(output_channel),\n",
    "                    )\n",
    "        self.res = nn.Sequential(\n",
    "                        nn.Conv1d(input_channel, output_channel, 1),\n",
    "                        nn.BatchNorm1d(output_channel),\n",
    "                    )\n",
    "\n",
    "        self.x_mlp = nn.Sequential(\n",
    "                        nn.Conv2d(3, (output_channel//3)*3, 1),\n",
    "                        nn.BatchNorm2d((output_channel//3)*3),\n",
    "                        nn.ReLU(True)\n",
    "                    )\n",
    "        \n",
    "        self.invres = nn.ModuleList()\n",
    "        for i in range(inverse_num):\n",
    "            self.invres.append(InvResMLP(output_channel))\n",
    "        \n",
    "        self.knn = KNN(k=k, transpose_mode=True)\n",
    "        \n",
    "    def forward(self, x, feature):   # [B, 3, N]  [B, C, N]\n",
    "        _, _, N = x.shape\n",
    "        \n",
    "        identity = feature   # [B, C, N]\n",
    "        \n",
    "        _, neighbor_index = self.knn(x.permute(0, 2, 1).contiguous(), x.permute(0, 2, 1).contiguous())  # [B, N, k]\n",
    "\n",
    "        # grouping\n",
    "        knn_x, relative_x, local_rep, _, _ = LPR(x, neighbor_index)   # [B, 3, N, k]  [B, 3, N, k]  [B, 3, N, k]\n",
    "        knn_feature = index_points(feature, neighbor_index) - feature.unsqueeze(-1)   # [B, C, N, k]\n",
    "        \n",
    "        x_enc = torch.cat([relative_x, local_rep], dim=1)   # [B, 6, N, k]\n",
    "\n",
    "        scaling = self.mlp_f1(knn_feature)   # [B, 1, N, k]\n",
    "        feature = self.mlp_f2(knn_feature)   # [B, out//2, N, k]\n",
    "        rotation = (feature.permute(0, 2, 3, 1) @ self.Rw).permute(0, 3, 1, 2)   # [B, 2, N, k]\n",
    "\n",
    "        feature = torch.cat([x_enc, knn_feature, scaling, rotation], dim=1)   # [B, C+9, N, k]\n",
    "        feature = self.mlp1(feature)   # [B, out, N, k]\n",
    "        feature = torch.max(feature, dim=-1)[0]   # [B, out, N]\n",
    "\n",
    "        # residual\n",
    "        feature = self.mlp2(feature)   # [B, out, N]\n",
    "        res = self.res(identity)   # [B, out, N]\n",
    "        feature = F.relu(feature+res, True)\n",
    "\n",
    "        x_encoding = self.x_mlp(relative_x)\n",
    "        for res in self.invres:\n",
    "            feature = res(relative_x, x_encoding, neighbor_index, feature)\n",
    "\n",
    "        # sub-sample\n",
    "        sample_num = N//self.stride\n",
    "        fps_idx = fps(x.permute(0, 2, 1).contiguous(), sample_num)\n",
    "        sub_x = pointnet2_utils.gather_operation(x, fps_idx)   # [B, 3, S]\n",
    "        sub_feature = pointnet2_utils.gather_operation(feature, fps_idx)    # [B, C, S]\n",
    "        \n",
    "        return sub_feature, sub_x, neighbor_index   # [B, out, S]  [B, 3, S]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885989ac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ed5f56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialization(pos, feat, x_res=None, order=\"z\", layers_outputs=[], grid_size=0.02):\n",
    "    '''\n",
    "    Args:\n",
    "        order(str): [ \"xyz\", \"xzy\", \"yxz\", \"yzx\", \"zxy\", \"zyx\", \"hilbert\", \"z\", \"z-trans\" ]\n",
    "    '''\n",
    "    bs, n_p, _ = pos.size()\n",
    "    if not isinstance(order, list):\n",
    "        order = [order]\n",
    "\n",
    "    scaled_coord = pos / grid_size\n",
    "    grid_coord = torch.floor(scaled_coord).to(torch.int64)\n",
    "    min_coord = grid_coord.min(dim=1, keepdim=True)[0]\n",
    "    grid_coord = grid_coord - min_coord\n",
    "\n",
    "    batch_idx = torch.arange(0, pos.shape[0], 1.0).unsqueeze(1).repeat(1, pos.shape[1]).to(torch.int64).to(pos.device)\n",
    "\n",
    "    point_dict = {'batch': batch_idx.flatten(), 'grid_coord': grid_coord.flatten(0, 1), }\n",
    "    point_dict = Point(**point_dict)\n",
    "    point_dict.serialization(order=order)\n",
    "\n",
    "    order = point_dict.serialized_order\n",
    "    inverse_order = point_dict.serialized_inverse\n",
    "\n",
    "    pos = pos.flatten(0, 1)[order].reshape(bs, n_p, -1).contiguous()\n",
    "    feat = feat.flatten(0, 1)[order].reshape(bs, n_p, -1).contiguous()\n",
    "    if x_res is not None:\n",
    "        x_res = x_res.flatten(0, 1)[order].reshape(bs, n_p, -1).contiguous()\n",
    "\n",
    "    for i in range(len(layers_outputs)):\n",
    "        layers_outputs[i] = layers_outputs[i].flatten(0, 1)[order].reshape(bs, n_p, -1).contiguous()\n",
    "    return pos, feat, x_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded97043",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Mamba Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5302bcf-a145-4b8f-a8ec-3bab97fc7b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "try:\n",
    "    from mamba_ssm.ops.triton.layernorm import RMSNorm, layer_norm_fn, rms_norm_fn\n",
    "except ImportError:\n",
    "    RMSNorm, layer_norm_fn, rms_norm_fn = None, None, None\n",
    "from timm.models.layers import DropPath\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(\n",
    "        self, dim, mixer_cls, norm_cls=nn.LayerNorm, fused_add_norm=False,\n",
    "            residual_in_fp32=False, drop_path=0.\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Simple block wrapping a mixer class with LayerNorm/RMSNorm and residual connection\"\n",
    "\n",
    "        This Block has a slightly different structure compared to a regular\n",
    "        prenorm Transformer block.\n",
    "        The standard block is: LN -> MHA/MLP -> Add.\n",
    "        [Ref: https://arxiv.org/abs/2002.04745]\n",
    "        Here we have: Add -> LN -> Mixer, returning both\n",
    "        the hidden_states (output of the mixer) and the residual.\n",
    "        This is purely for performance reasons, as we can fuse add and LayerNorm.\n",
    "        The residual needs to be provided (except for the very first block).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.residual_in_fp32 = residual_in_fp32\n",
    "        self.fused_add_norm = fused_add_norm\n",
    "        self.mixer = mixer_cls(dim)\n",
    "        self.norm = norm_cls(dim)\n",
    "        \n",
    "        # drop path \n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        if self.fused_add_norm:\n",
    "            assert RMSNorm is not None, \"RMSNorm import fails\"\n",
    "            assert isinstance(\n",
    "                self.norm, (nn.LayerNorm, RMSNorm)\n",
    "            ), \"Only LayerNorm and RMSNorm are supported for fused_add_norm\"\n",
    "\n",
    "    def forward(\n",
    "        self, hidden_states: Tensor, residual: Optional[Tensor] = None, inference_params=None\n",
    "    ):\n",
    "        r\"\"\"Pass the input through the encoder layer.\n",
    "\n",
    "        Args:\n",
    "            hidden_states: the sequence to the encoder layer (required).\n",
    "            residual: hidden_states = Mixer(LN(residual))\n",
    "        \"\"\"\n",
    "        if not self.fused_add_norm:\n",
    "            residual = (self.drop_path(hidden_states) + residual) if residual is not None else hidden_states\n",
    "            hidden_states = self.norm(residual.to(dtype=self.norm.weight.dtype))\n",
    "            if self.residual_in_fp32:\n",
    "                residual = residual.to(torch.float32)\n",
    "        else:\n",
    "            fused_add_norm_fn = rms_norm_fn if isinstance(self.norm, RMSNorm) else layer_norm_fn\n",
    "            hidden_states, residual = fused_add_norm_fn(\n",
    "                self.drop_path(hidden_states),\n",
    "                self.norm.weight,\n",
    "                self.norm.bias,\n",
    "                residual=residual,\n",
    "                prenorm=True,\n",
    "                residual_in_fp32=self.residual_in_fp32,\n",
    "                eps=self.norm.eps,\n",
    "            )\n",
    "        hidden_states = self.mixer(hidden_states, inference_params=inference_params)\n",
    "        return hidden_states, residual\n",
    "\n",
    "    def allocate_inference_cache(self, batch_size, max_seqlen, dtype=None, **kwargs):\n",
    "        return self.mixer.allocate_inference_cache(batch_size, max_seqlen, dtype=dtype, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca989974-7854-4f1b-8ae7-24b495bb54d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "from mamba_ssm.modules.mamba_simple import Mamba\n",
    "\n",
    "def create_block(\n",
    "        d_model,\n",
    "        ssm_cfg=None,\n",
    "        norm_epsilon=1e-5,\n",
    "        rms_norm=False,\n",
    "        residual_in_fp32=False,\n",
    "        fused_add_norm=False,\n",
    "        layer_idx=None,\n",
    "        drop_path=0.,\n",
    "        device=None,\n",
    "        dtype=None,\n",
    "):\n",
    "    if ssm_cfg is None:\n",
    "        ssm_cfg = {}\n",
    "    factory_kwargs = {\"device\": device, \"dtype\": dtype}\n",
    "\n",
    "    mixer_cls = partial(Mamba, layer_idx=layer_idx, **ssm_cfg, **factory_kwargs)\n",
    "    norm_cls = partial(\n",
    "        nn.LayerNorm if not rms_norm else RMSNorm, eps=norm_epsilon, **factory_kwargs\n",
    "    )\n",
    "    block = Block(\n",
    "        d_model,\n",
    "        mixer_cls,\n",
    "        norm_cls=norm_cls,\n",
    "        fused_add_norm=fused_add_norm,\n",
    "        residual_in_fp32=residual_in_fp32,\n",
    "        drop_path=drop_path,\n",
    "    )\n",
    "    block.layer_idx = layer_idx\n",
    "    return block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a43c25b",
   "metadata": {},
   "source": [
    "#### Mamba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "823c4b10-5340-4370-b501-45b1b2c585f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_weights(\n",
    "        module,\n",
    "        n_layer,\n",
    "        initializer_range=0.02,  # Now only used for embedding layer.\n",
    "        rescale_prenorm_residual=True,\n",
    "        n_residuals_per_layer=1,  # Change to 2 if we have MLP\n",
    "):\n",
    "    if isinstance(module, nn.Linear):\n",
    "        if module.bias is not None:\n",
    "            if not getattr(module.bias, \"_no_reinit\", False):\n",
    "                nn.init.zeros_(module.bias)\n",
    "    elif isinstance(module, nn.Embedding):\n",
    "        nn.init.normal_(module.weight, std=initializer_range)\n",
    "\n",
    "    if rescale_prenorm_residual:\n",
    "        # Reinitialize selected weights subject to the OpenAI GPT-2 Paper Scheme:\n",
    "        #   > A modified initialization which accounts for the accumulation on the residual path with model depth. Scale\n",
    "        #   > the weights of residual layers at initialization by a factor of 1/√N where N is the # of residual layers.\n",
    "        #   >   -- GPT-2 :: https://openai.com/blog/better-language-models/\n",
    "        #\n",
    "        # Reference (Megatron-LM): https://github.com/NVIDIA/Megatron-LM/blob/main/megatron/model/gpt_model.py\n",
    "        for name, p in module.named_parameters():\n",
    "            if name in [\"out_proj.weight\", \"fc2.weight\"]:\n",
    "                # Special Scaled Initialization --> There are 2 Layer Norms per Transformer Block\n",
    "                # Following Pytorch init, except scale by 1/sqrt(2 * n_layer)\n",
    "                # We need to reinit p since this code could be called multiple times\n",
    "                # Having just p *= scale would repeatedly scale it down\n",
    "                nn.init.kaiming_uniform_(p, a=math.sqrt(5))\n",
    "                with torch.no_grad():\n",
    "                    p /= math.sqrt(n_residuals_per_layer * n_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23725aaa-b57a-4387-a14f-2fa7d3db01cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class MixerModel(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            d_model: int,\n",
    "            n_layer: int,\n",
    "            ssm_cfg=None,\n",
    "            norm_epsilon: float = 1e-5,\n",
    "            rms_norm: bool = False,\n",
    "            initializer_cfg=None,\n",
    "            fused_add_norm=False,\n",
    "            residual_in_fp32=False,\n",
    "            drop_out_in_block: int = 0.,\n",
    "            drop_path: int = 0.1,\n",
    "            device=None,\n",
    "            dtype=None,\n",
    "    ) -> None:\n",
    "        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n",
    "        super().__init__()\n",
    "        self.residual_in_fp32 = residual_in_fp32\n",
    "\n",
    "        # self.embedding = nn.Embedding(vocab_size, d_model, **factory_kwargs)\n",
    "\n",
    "        # We change the order of residual and layer norm:\n",
    "        # Instead of LN -> Attn / MLP -> Add, we do:\n",
    "        # Add -> LN -> Attn / MLP / Mixer, returning both the residual branch (output of Add) and\n",
    "        # the main branch (output of MLP / Mixer). The model definition is unchanged.\n",
    "        # This is for performance reason: we can fuse add + layer_norm.\n",
    "        self.fused_add_norm = fused_add_norm\n",
    "        if self.fused_add_norm:\n",
    "            if layer_norm_fn is None or rms_norm_fn is None:\n",
    "                raise ImportError(\"Failed to import Triton LayerNorm / RMSNorm kernels\")\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                create_block(\n",
    "                    d_model,\n",
    "                    ssm_cfg=ssm_cfg,\n",
    "                    norm_epsilon=norm_epsilon,\n",
    "                    rms_norm=rms_norm,\n",
    "                    residual_in_fp32=residual_in_fp32,\n",
    "                    fused_add_norm=fused_add_norm,\n",
    "                    layer_idx=i,\n",
    "                    drop_path=drop_path,\n",
    "                    **factory_kwargs,\n",
    "                )\n",
    "                for i in range(n_layer)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.norm_f = (nn.LayerNorm if not rms_norm else RMSNorm)(\n",
    "            d_model, eps=norm_epsilon, **factory_kwargs\n",
    "        )\n",
    "\n",
    "        self.apply(\n",
    "            partial(\n",
    "                _init_weights,\n",
    "                n_layer=n_layer,\n",
    "                **(initializer_cfg if initializer_cfg is not None else {}),\n",
    "            )\n",
    "        )\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.drop_out_in_block = nn.Dropout(drop_out_in_block) if drop_out_in_block > 0. else nn.Identity()\n",
    "\n",
    "    def allocate_inference_cache(self, batch_size, max_seqlen, dtype=None, **kwargs):\n",
    "        return {\n",
    "            i: layer.allocate_inference_cache(batch_size, max_seqlen, dtype=dtype, **kwargs)\n",
    "            for i, layer in enumerate(self.layers)\n",
    "        }\n",
    "\n",
    "    def forward(self, input_ids, pos, inference_params=None):\n",
    "        hidden_states = input_ids  # + pos\n",
    "        residual = None\n",
    "        hidden_states = hidden_states + pos\n",
    "        for layer in self.layers:                   # hidden_states: all 32, 192, 384\n",
    "            hidden_states, residual = layer(\n",
    "                hidden_states, residual, inference_params=inference_params\n",
    "            )\n",
    "            hidden_states = self.drop_out_in_block(hidden_states)\n",
    "        if not self.fused_add_norm:\n",
    "            residual = (hidden_states + residual) if residual is not None else hidden_states\n",
    "            hidden_states = self.norm_f(residual.to(dtype=self.norm_f.weight.dtype))\n",
    "        else:\n",
    "            # Set prenorm=False here since we don't need the residual\n",
    "            fused_add_norm_fn = rms_norm_fn if isinstance(self.norm_f, RMSNorm) else layer_norm_fn\n",
    "            hidden_states = fused_add_norm_fn(\n",
    "                hidden_states,\n",
    "                self.norm_f.weight,\n",
    "                self.norm_f.bias,\n",
    "                eps=self.norm_f.eps,\n",
    "                residual=residual,\n",
    "                prenorm=False,\n",
    "                residual_in_fp32=self.residual_in_fp32,\n",
    "            )\n",
    "\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ce93f7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### FeaturePropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2e08434",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturePropagation(nn.Module):\n",
    "    '''\n",
    "    def __init__(self, input_channel, mlp)\n",
    "    \n",
    "    def forward(self, coords1, coords2, points1, points2)\n",
    "        输入：\n",
    "            某一层输入：coords1  [B, C, N], points1  [B, D, N]\n",
    "            某一层输出：coords2  [B, C, S]，points2  [B, D', S]\n",
    "        返回：\n",
    "            new_points  [B, D'', N]\n",
    "    '''\n",
    "    def __init__(self, input_channel, mlp):\n",
    "        super().__init__()\n",
    "        self.mlp_conv = nn.ModuleList()\n",
    "        self.mlp_bn = nn.ModuleList()\n",
    "        for output_channel in mlp:\n",
    "            self.mlp_conv.append(nn.Conv1d(input_channel, output_channel, 1, bias=False))\n",
    "            self.mlp_bn.append(nn.BatchNorm1d(output_channel))\n",
    "            input_channel = output_channel\n",
    "\n",
    "    def forward(self, coords1, coords2, points1, points2):\n",
    "        '''                                                     第一层          第二层          第三层          第四层\n",
    "            coords1：[B, C, N]   Set Abstraction的输入     eg.  [B, 3, 2048]    [B, 3, 1024]    [B, 3, 256]     [B, 3, 64]\n",
    "            coords2：[B, C, S]   Set Abstraction的输出     eg.  [B, 3, 1024]    [B, 3, 256]     [B, 3, 64]      [B, 3, 16]\n",
    "            points1：[B, D, N]   Set Abstraction的输入     eg.  [B, 9, 2048]    [B, 64, 1024]   [B, 128, 256]   [B, 256, 64]\n",
    "            points2：[B, D', S]  Set Abstraction的输出     eg.  [B, 64, 1024]   [B, 128, 256]   [B, 256, 64]    [B, 512, 16]\n",
    "        '''\n",
    "        # 以第四层为例标明注释\n",
    "        \n",
    "        coords1 = coords1.permute(0, 2, 1)    # [B, 64, 3]\n",
    "        coords2 = coords2.permute(0, 2, 1)    # [B, 16, 3]\n",
    "        \n",
    "        dists, index = three_nn(coords1, coords2)   # [B, 64, 3]  [B, 16, 3]\n",
    "        \n",
    "        dist_recip = 1 / (dists + 1e-8)\n",
    "        norm = torch.sum(dist_recip, -1, keepdim=True)\n",
    "        weight = dist_recip / norm    # [B, 64, 3]\n",
    "        \n",
    "        interpolated_points = three_interpolate(points2, index, weight)\n",
    "\n",
    "        new_points = torch.cat([points1, interpolated_points], dim=1)   # [B, 768, 64]\n",
    "\n",
    "        for conv,bn in zip(self.mlp_conv, self.mlp_bn):\n",
    "            new_points = F.relu(bn(conv(new_points)), inplace=True)\n",
    "        # 最后输出new_points.shape: [B, 256, 64]\n",
    "        \n",
    "        return new_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d427d0a3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1b0b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98f50c5",
   "metadata": {},
   "source": [
    "### Semantic Seg Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d88c2d9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b41112",
   "metadata": {},
   "outputs": [],
   "source": [
    "def caculate_sem_IOU(pred, label):\n",
    "    '''\n",
    "    pred: [B × 4096]\n",
    "    label: [B × 4096]\n",
    "    '''\n",
    "    I_all = torch.zeros(13)\n",
    "    U_all = torch.zeros(13)\n",
    "\n",
    "    for sem in range(13):\n",
    "        I = torch.sum(torch.logical_and(pred==sem, label==sem))\n",
    "        U = torch.sum(torch.logical_or(pred==sem, label==sem))\n",
    "        I_all[sem] = I_all[sem] + I\n",
    "        U_all[sem] = U_all[sem] + U\n",
    "    \n",
    "    return I_all / U_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3797a673",
   "metadata": {},
   "source": [
    "#### Train & Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508528bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    setup_seed(1)\n",
    "    \n",
    "    transform = Compose([RandomRotate(), RandomScale([0.9, 1.1]), RandomFlip(0.5), RandomJitter(0.005, 0.02), \n",
    "                         RandomDropColor()])\n",
    "\n",
    "    train_loader = DataLoader(S3DISDataset(num_point=40960, split=\"train\", transform=transform), \n",
    "                              2, True, drop_last=False, num_workers=8, pin_memory=True)\n",
    "    test_loader = DataLoader(S3DISDataset(num_point=40960, split=\"test\", transform=None),\n",
    "                             4, True, drop_last=True, num_workers=8, pin_memory=True)\n",
    "\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    \n",
    "    START_EPOCH = 0\n",
    "    EPOCH = 100\n",
    "    lr = 0.01\n",
    "    \n",
    "    model = semseg_network().to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr, weight_decay=1e-4)\n",
    "    # scheduler = MultiStepLR(optimizer, [int(EPOCH*0.6), int(EPOCH*0.8)], gamma=0.1)\n",
    "    scheduler = CosineAnnealingLR(optimizer, EPOCH, 1e-5)\n",
    "    criterion = cal_loss\n",
    "    \n",
    "    best_test_iou = 0\n",
    "    \n",
    "#     # 加载断点，继续训练\n",
    "#     path = \"./AnisoVector/semseg_last.pkl\"\n",
    "#     checkpoint = torch.load(path)\n",
    "#     model.load_state_dict(checkpoint[\"model\"])\n",
    "#     optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "#     scheduler.load_state_dict(checkpoint[\"scheduler\"])\n",
    "#     best_test_iou = checkpoint[\"best_test_iou\"]\n",
    "#     START_EPOCH = checkpoint[\"epoch\"] + 1\n",
    "    \n",
    "    for epoch in range(START_EPOCH, EPOCH):\n",
    "        '''\n",
    "        Train\n",
    "        '''\n",
    "        start_time = time()\n",
    "        \n",
    "        train_loss = 0\n",
    "        count = 0\n",
    "        train_pred_seg = []\n",
    "        train_true_seg = []\n",
    "        train_pred_iou = []\n",
    "        train_true_iou = []\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        for x, feature, semseg in tqdm(train_loader, total=len(train_loader)):\n",
    "\n",
    "            B = x.shape[0]\n",
    "            \n",
    "            x = x.to(device).transpose(2, 1).float()\n",
    "            feature = feature.to(device).transpose(2, 1).float()\n",
    "            semseg = semseg.to(device).int()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            pred_semseg = model(x, feature)\n",
    "            \n",
    "            pred_semseg = pred_semseg.transpose(2, 1).contiguous()  # [B, 4096, 13]\n",
    "            \n",
    "            loss = criterion(pred_semseg.view(-1, 13), semseg.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            count = count + B\n",
    "        \n",
    "            pred_semseg_class = pred_semseg.max(-1)[1]   # [B, 4096]\n",
    "            \n",
    "            train_loss = train_loss + loss.item() * B\n",
    "            \n",
    "            pred_semseg_class = pred_semseg_class.cpu()\n",
    "            semseg = semseg.cpu()\n",
    "            \n",
    "            train_pred_seg.append(pred_semseg_class.view(-1))   # [B×4096]\n",
    "            train_true_seg.append(semseg.view(-1))   # [B×4096]\n",
    "        \n",
    "        end_time = time()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        train_pred_seg = torch.cat(train_pred_seg)\n",
    "        train_true_seg = torch.cat(train_true_seg)\n",
    "        \n",
    "        acc = accuracy_score(train_true_seg, train_pred_seg)\n",
    "        avg_acc = balanced_accuracy_score(train_true_seg, train_pred_seg)\n",
    "        \n",
    "        iou = caculate_sem_IOU(train_pred_seg, train_true_seg)\n",
    "        \n",
    "        outstr = \"Train: %s, loss: %s, acc: %s, avg acc: %s, mIOU: %s, time-consuming: %s\" % (str(epoch), str(train_loss / count),\n",
    "                                                                                                  str(acc), str(avg_acc), \n",
    "                                                                                                   str(torch.mean(iou).item()), str(end_time-start_time))\n",
    "        print(outstr)\n",
    "        with open(\"./PointMamba/train.txt\", \"a\") as f:\n",
    "            f.write(outstr)\n",
    "            f.write(\"\\n\")\n",
    "        \n",
    "        '''\n",
    "        Val\n",
    "        '''\n",
    "        val_start = time()\n",
    "        \n",
    "        test_loss = 0\n",
    "        count = 0\n",
    "        test_pred_seg = []\n",
    "        test_true_seg = []\n",
    "        test_pred_iou = []\n",
    "        test_true_iou = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for x, feature, semseg in test_loader:\n",
    "                B = x.shape[0]\n",
    "\n",
    "                x = x.to(device).transpose(2, 1).float()\n",
    "                feature = feature.to(device).transpose(2, 1).float()\n",
    "                semseg = semseg.to(device).int()\n",
    "                \n",
    "                pred_semseg = model(x, feature)\n",
    "\n",
    "                pred_semseg = pred_semseg.transpose(2, 1).contiguous()  # [B, 4096, 13]\n",
    "\n",
    "                loss = criterion(pred_semseg.view(-1, 13), semseg.view(-1))\n",
    "\n",
    "                count = count + B\n",
    "\n",
    "                pred_semseg_class = pred_semseg.max(-1)[1]   # [B, 4096]\n",
    "\n",
    "                test_loss = test_loss + loss.item() * B\n",
    "\n",
    "                pred_semseg_class = pred_semseg_class.cpu()\n",
    "                semseg = semseg.cpu()\n",
    "\n",
    "                test_pred_seg.append(pred_semseg_class.view(-1))   # [B×4096]\n",
    "                test_true_seg.append(semseg.view(-1))   # [B×4096]\n",
    "            \n",
    "            val_end = time()\n",
    "\n",
    "            test_pred_seg = torch.cat(test_pred_seg)\n",
    "            test_true_seg = torch.cat(test_true_seg)\n",
    "\n",
    "            acc = accuracy_score(test_true_seg, test_pred_seg)\n",
    "            avg_acc = balanced_accuracy_score(test_true_seg, test_pred_seg)\n",
    "\n",
    "            iou = caculate_sem_IOU(test_pred_seg, test_true_seg)\n",
    "\n",
    "            outstr = \"Test: %s, loss: %s, acc: %s, avg acc: %s, mIOU: %s, time-consuming: %s\" % (str(epoch), str(test_loss / count),\n",
    "                                                                                                      str(acc), str(avg_acc), \n",
    "                                                                                                       str(torch.mean(iou).item()), str(val_end-val_start))\n",
    "            print(outstr)\n",
    "            with open(\"./PointMamba/test.txt\", \"a\") as f:\n",
    "                f.write(outstr)\n",
    "                f.write(\"\\n\")\n",
    "\n",
    "            if torch.mean(iou) > best_test_iou:\n",
    "                best_test_iou = torch.mean(iou)\n",
    "\n",
    "                # 保存模型的各个参数（断点训练需要）\n",
    "                checkpoint = {\n",
    "                            \"model\": model.state_dict(),\n",
    "                            'optimizer': optimizer.state_dict(),\n",
    "                            \"epoch\": epoch,\n",
    "                            'scheduler': scheduler.state_dict(),\n",
    "                            'best_test_iou': best_test_iou\n",
    "                        }\n",
    "                torch.save(checkpoint, './PointMamba/semseg_'+str(epoch)+\".pkl\")\n",
    "            # 保存最新模型\n",
    "            checkpoint = {\n",
    "                        \"model\": model.state_dict(),\n",
    "                        'optimizer': optimizer.state_dict(),\n",
    "                        \"epoch\": epoch,\n",
    "                        'scheduler': scheduler.state_dict(),\n",
    "                        'best_test_iou': best_test_iou\n",
    "                    }\n",
    "            torch.save(checkpoint, './PointMamba/semseg_last.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbb92b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f105f9e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac39c381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc36202",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e65fd2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7704f11b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeec1507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c2e484",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
