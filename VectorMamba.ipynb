{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37f8e082",
   "metadata": {},
   "source": [
    "### 网络结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bbe4f8",
   "metadata": {},
   "source": [
    "#### LRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5f293b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LPR(x, index):   # [B, 3, N]\n",
    "    '''\n",
    "    输入:\n",
    "        x: [B, 3, N]\n",
    "        index: [B, N, k]\n",
    "    返回:\n",
    "        knn_x, relative_x, local_rep, exp_x, ratio_volume   # [B, 3, N, k]  [B, 3, N, k]   [B, 3, N, k]  [B, 1, N, k]  [B, N]\n",
    "    '''\n",
    "    B, _, N = x.shape\n",
    "    k = index.shape[-1]\n",
    "\n",
    "    knn_x = index_points(x, index)   # [B, 3, N, k]\n",
    "    central_x = x.unsqueeze(-1).repeat(1, 1, 1, k)   # [B, 3, N, k]\n",
    "\n",
    "    relative_x = central_x - knn_x   # [B, 3, N, k]\n",
    "\n",
    "    # 相对点的 alpha 和 beta\n",
    "    alpha = torch.atan2(relative_x[:, 1, :, :], relative_x[:, 0, :, :]).reshape(B, 1, N, k)   # [B, 1, N, k]\n",
    "    xy_dist = torch.sqrt(torch.sum(torch.square(relative_x[:, :2, :, :]), dim=1)).reshape(B, 1, N, k)   # [B, 1, N, k]\n",
    "    beta = torch.atan2(relative_x[:, 2:, :, :], xy_dist).reshape(B, 1, N, k)   # [B, 1, N, k]\n",
    "    relative_dist = torch.sqrt(torch.sum(torch.square(relative_x), dim=1)).reshape(B, 1, N, k)   # [B, 1, N, k]\n",
    "\n",
    "    exp_x = torch.exp(-relative_dist)   # [B, 1, N, k]\n",
    "    local_volume = torch.pow(torch.max(relative_dist.squeeze(1), dim=-1)[0], 3)   # [B, N]  每个neighbor的体积\n",
    "\n",
    "    # 质心点的 alpha 和 beta\n",
    "    barycentrer_x = torch.mean(knn_x, dim=-1)   # [B, 3, N]  质心\n",
    "    direction_relative = x - barycentrer_x   # [B, 3, N]\n",
    "    direction_relative = direction_relative.unsqueeze(-1).repeat(1, 1, 1, k)   # [B, 3, N, k]\n",
    "    barycentrer_alpha = torch.atan2(direction_relative[:, 1, :, :], direction_relative[:, 0, :, :]).reshape(B, 1, N, k)   # [B, 1, N, k]\n",
    "    xy_dist = torch.sqrt(torch.sum(torch.square(direction_relative[:, :2, :, :]), dim=1)).reshape(B, 1, N, k)   # [B, 1, N, k]\n",
    "    barycentrer_beta = torch.atan2(direction_relative[:, 2:, :, :], xy_dist).reshape(B, 1, N, k)   # [B, 1, N, k]\n",
    "\n",
    "    angle = torch.cat([alpha-barycentrer_alpha, beta-barycentrer_beta], dim=1)   # [B, 2, N, k]\n",
    "\n",
    "    local_rep = torch.cat([relative_dist, angle], dim=1)   # [B, 3, N, k]\n",
    "\n",
    "    global_dist = torch.sqrt(torch.sum(torch.square(x), dim=1))   # [B, N]\n",
    "    global_volume = torch.pow(torch.max(global_dist, dim=-1, keepdim=True)[0], 3)   # [B, 1]\n",
    "\n",
    "    ratio_volume = local_volume / global_volume   # [B, N]\n",
    "\n",
    "    return knn_x, relative_x, local_rep, exp_x, ratio_volume   # [B, 3, N, k]  [B, 3, N, k]   [B, 3, N, k]  [B, 1, N, k]  [B, N]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f946ed07",
   "metadata": {},
   "source": [
    "#### FlaResMLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37c1e81b-735a-40cb-9194-14d8a3855815",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvResMLP(nn.Module):\n",
    "    '''\n",
    "    def __init__(self, input_channel):\n",
    "    \n",
    "    def forward(self, x, neighbor_index, feature):   # [B, 3, N]  [B, N, k]  [B, C, N]\n",
    "    \n",
    "    返回:\n",
    "        feature    # [B, C, N]\n",
    "    '''\n",
    "    def __init__(self, input_channel):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_channel = input_channel\n",
    "        \n",
    "        self.mlpf = nn.Sequential(\n",
    "                        nn.Conv1d(input_channel, (input_channel//3)*3, 1, bias=False),\n",
    "                        nn.BatchNorm1d((input_channel//3)*3),\n",
    "                        nn.LeakyReLU(0.2, True)\n",
    "                    )\n",
    "        \n",
    "        self.mlp1 = nn.Sequential(\n",
    "                       nn.Conv1d((input_channel//3)*3, 4*input_channel, 1, bias=False),\n",
    "                       nn.BatchNorm1d(4*input_channel),\n",
    "                       nn.ReLU(True)\n",
    "                    )\n",
    "        \n",
    "        self.mlp2 = nn.Sequential(\n",
    "                       nn.Conv1d(4*input_channel, input_channel, 1, bias=False),\n",
    "                       nn.BatchNorm1d(input_channel),\n",
    "                    )\n",
    "    \n",
    "    def forward(self, relative_x, x_encoding, neighbor_index, feature):   # [B, 3, N, k]  [B, C, N, k]  [B, N, k]  [B, C, N]\n",
    "        identity = feature\n",
    "\n",
    "        feature = self.mlpf(feature)   # [B, C, N]\n",
    "        knn_feature = index_points(feature, neighbor_index)   # [B, C, N, k]\n",
    "        feature = x_encoding + knn_feature   # [B, C, N, k]\n",
    "        \n",
    "        B, C, N, k = feature.shape\n",
    "        \n",
    "        x_en = relative_x.unsqueeze(2).repeat(1, 1, self.input_channel//3, 1, 1).reshape(B, C, N, k)\n",
    "        feature = x_en * feature   # [B, C, N, k]\n",
    "        \n",
    "        feature = torch.max(feature, dim=-1)[0]   # [B, C, N]\n",
    "        \n",
    "        feature = self.mlp2(self.mlp1(feature))   # [B, C, N]\n",
    "        \n",
    "        # residual\n",
    "        feature =  F.relu(feature+identity, inplace=True)   # [B, C, N]\n",
    "        \n",
    "        return feature    # [B, C, N]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8a9343",
   "metadata": {},
   "source": [
    "#### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c4b3dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    '''\n",
    "    def __init__(self, input_channel, output_channel, k, stride, inverse_num):\n",
    "    \n",
    "    def forward(self, x, feature):   # [B, 3, N]  [B, C, N]\n",
    "    \n",
    "    return:\n",
    "        feature, sub_x, neighbor_index   # [B, out, S]  [B, 3, S]\n",
    "    '''\n",
    "    def __init__(self, input_channel, output_channel, k, stride, inverse_num):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.k = k\n",
    "        self.stride = stride\n",
    "\n",
    "        self.mlp_f1 = nn.Sequential(\n",
    "                        nn.Conv2d(input_channel, 1, 1),\n",
    "                    )\n",
    "        \n",
    "        self.mlp_f2 = nn.Sequential(\n",
    "                        nn.Conv2d(input_channel, output_channel//2, 1),\n",
    "                        nn.BatchNorm2d(output_channel//2),\n",
    "                        nn.ReLU(True)\n",
    "                    )\n",
    "\n",
    "        self.Rw = nn.Parameter(torch.randn(output_channel//2, 2))\n",
    "        \n",
    "        self.mlp1 = nn.Sequential(\n",
    "                        nn.Conv2d(input_channel+9, output_channel, 1),\n",
    "                        nn.BatchNorm2d(output_channel),\n",
    "                        nn.ReLU(True)\n",
    "                    )\n",
    "        \n",
    "        self.mlp2 = nn.Sequential(\n",
    "                        nn.Conv1d(output_channel, output_channel, 1),\n",
    "                        nn.BatchNorm1d(output_channel),\n",
    "                    )\n",
    "        self.res = nn.Sequential(\n",
    "                        nn.Conv1d(input_channel, output_channel, 1),\n",
    "                        nn.BatchNorm1d(output_channel),\n",
    "                    )\n",
    "\n",
    "        self.x_mlp = nn.Sequential(\n",
    "                        nn.Conv2d(3, (output_channel//3)*3, 1),\n",
    "                        nn.BatchNorm2d((output_channel//3)*3),\n",
    "                        nn.ReLU(True)\n",
    "                    )\n",
    "        \n",
    "        self.invres = nn.ModuleList()\n",
    "        for i in range(inverse_num):\n",
    "            self.invres.append(InvResMLP(output_channel))\n",
    "        \n",
    "        self.knn = KNN(k=k, transpose_mode=True)\n",
    "        \n",
    "    def forward(self, x, feature):   # [B, 3, N]  [B, C, N]\n",
    "        _, _, N = x.shape\n",
    "        \n",
    "        identity = feature   # [B, C, N]\n",
    "        \n",
    "        _, neighbor_index = self.knn(x.permute(0, 2, 1).contiguous(), x.permute(0, 2, 1).contiguous())  # [B, N, k]\n",
    "\n",
    "        # grouping\n",
    "        knn_x, relative_x, local_rep, _, _ = LPR(x, neighbor_index)   # [B, 3, N, k]  [B, 3, N, k]  [B, 3, N, k]\n",
    "        knn_feature = index_points(feature, neighbor_index) - feature.unsqueeze(-1)   # [B, C, N, k]\n",
    "        \n",
    "        x_enc = torch.cat([relative_x, local_rep], dim=1)   # [B, 6, N, k]\n",
    "\n",
    "        scaling = self.mlp_f1(knn_feature)   # [B, 1, N, k]\n",
    "        feature = self.mlp_f2(knn_feature)   # [B, out//2, N, k]\n",
    "        rotation = (feature.permute(0, 2, 3, 1) @ self.Rw).permute(0, 3, 1, 2)   # [B, 2, N, k]\n",
    "\n",
    "        feature = torch.cat([x_enc, knn_feature, scaling, rotation], dim=1)   # [B, C+9, N, k]\n",
    "        feature = self.mlp1(feature)   # [B, out, N, k]\n",
    "        feature = torch.max(feature, dim=-1)[0]   # [B, out, N]\n",
    "\n",
    "        # residual\n",
    "        feature = self.mlp2(feature)   # [B, out, N]\n",
    "        res = self.res(identity)   # [B, out, N]\n",
    "        feature = F.relu(feature+res, True)\n",
    "\n",
    "        x_encoding = self.x_mlp(relative_x)\n",
    "        for res in self.invres:\n",
    "            feature = res(relative_x, x_encoding, neighbor_index, feature)\n",
    "\n",
    "        # sub-sample\n",
    "        sample_num = N//self.stride\n",
    "        fps_idx = fps(x.permute(0, 2, 1).contiguous(), sample_num)\n",
    "        sub_x = pointnet2_utils.gather_operation(x, fps_idx)   # [B, 3, S]\n",
    "        sub_feature = pointnet2_utils.gather_operation(feature, fps_idx)    # [B, C, S]\n",
    "        \n",
    "        return sub_feature, sub_x, neighbor_index   # [B, out, S]  [B, 3, S]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885989ac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ed5f56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialization(pos, feat, x_res=None, order=\"z\", layers_outputs=[], grid_size=0.02):\n",
    "    '''\n",
    "    Args:\n",
    "        order(str): [ \"xyz\", \"xzy\", \"yxz\", \"yzx\", \"zxy\", \"zyx\", \"hilbert\", \"z\", \"z-trans\" ]\n",
    "    '''\n",
    "    bs, n_p, _ = pos.size()\n",
    "    if not isinstance(order, list):\n",
    "        order = [order]\n",
    "\n",
    "    scaled_coord = pos / grid_size\n",
    "    grid_coord = torch.floor(scaled_coord).to(torch.int64)\n",
    "    min_coord = grid_coord.min(dim=1, keepdim=True)[0]\n",
    "    grid_coord = grid_coord - min_coord\n",
    "\n",
    "    batch_idx = torch.arange(0, pos.shape[0], 1.0).unsqueeze(1).repeat(1, pos.shape[1]).to(torch.int64).to(pos.device)\n",
    "\n",
    "    point_dict = {'batch': batch_idx.flatten(), 'grid_coord': grid_coord.flatten(0, 1), }\n",
    "    point_dict = Point(**point_dict)\n",
    "    point_dict.serialization(order=order)\n",
    "\n",
    "    order = point_dict.serialized_order\n",
    "    inverse_order = point_dict.serialized_inverse\n",
    "\n",
    "    pos = pos.flatten(0, 1)[order].reshape(bs, n_p, -1).contiguous()\n",
    "    feat = feat.flatten(0, 1)[order].reshape(bs, n_p, -1).contiguous()\n",
    "    if x_res is not None:\n",
    "        x_res = x_res.flatten(0, 1)[order].reshape(bs, n_p, -1).contiguous()\n",
    "\n",
    "    for i in range(len(layers_outputs)):\n",
    "        layers_outputs[i] = layers_outputs[i].flatten(0, 1)[order].reshape(bs, n_p, -1).contiguous()\n",
    "    return pos, feat, x_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded97043",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Mamba Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5302bcf-a145-4b8f-a8ec-3bab97fc7b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "try:\n",
    "    from mamba_ssm.ops.triton.layernorm import RMSNorm, layer_norm_fn, rms_norm_fn\n",
    "except ImportError:\n",
    "    RMSNorm, layer_norm_fn, rms_norm_fn = None, None, None\n",
    "from timm.models.layers import DropPath\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(\n",
    "        self, dim, mixer_cls, norm_cls=nn.LayerNorm, fused_add_norm=False,\n",
    "            residual_in_fp32=False, drop_path=0.\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Simple block wrapping a mixer class with LayerNorm/RMSNorm and residual connection\"\n",
    "\n",
    "        This Block has a slightly different structure compared to a regular\n",
    "        prenorm Transformer block.\n",
    "        The standard block is: LN -> MHA/MLP -> Add.\n",
    "        [Ref: https://arxiv.org/abs/2002.04745]\n",
    "        Here we have: Add -> LN -> Mixer, returning both\n",
    "        the hidden_states (output of the mixer) and the residual.\n",
    "        This is purely for performance reasons, as we can fuse add and LayerNorm.\n",
    "        The residual needs to be provided (except for the very first block).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.residual_in_fp32 = residual_in_fp32\n",
    "        self.fused_add_norm = fused_add_norm\n",
    "        self.mixer = mixer_cls(dim)\n",
    "        self.norm = norm_cls(dim)\n",
    "        \n",
    "        # drop path \n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        if self.fused_add_norm:\n",
    "            assert RMSNorm is not None, \"RMSNorm import fails\"\n",
    "            assert isinstance(\n",
    "                self.norm, (nn.LayerNorm, RMSNorm)\n",
    "            ), \"Only LayerNorm and RMSNorm are supported for fused_add_norm\"\n",
    "\n",
    "    def forward(\n",
    "        self, hidden_states: Tensor, residual: Optional[Tensor] = None, inference_params=None\n",
    "    ):\n",
    "        r\"\"\"Pass the input through the encoder layer.\n",
    "\n",
    "        Args:\n",
    "            hidden_states: the sequence to the encoder layer (required).\n",
    "            residual: hidden_states = Mixer(LN(residual))\n",
    "        \"\"\"\n",
    "        if not self.fused_add_norm:\n",
    "            residual = (self.drop_path(hidden_states) + residual) if residual is not None else hidden_states\n",
    "            hidden_states = self.norm(residual.to(dtype=self.norm.weight.dtype))\n",
    "            if self.residual_in_fp32:\n",
    "                residual = residual.to(torch.float32)\n",
    "        else:\n",
    "            fused_add_norm_fn = rms_norm_fn if isinstance(self.norm, RMSNorm) else layer_norm_fn\n",
    "            hidden_states, residual = fused_add_norm_fn(\n",
    "                self.drop_path(hidden_states),\n",
    "                self.norm.weight,\n",
    "                self.norm.bias,\n",
    "                residual=residual,\n",
    "                prenorm=True,\n",
    "                residual_in_fp32=self.residual_in_fp32,\n",
    "                eps=self.norm.eps,\n",
    "            )\n",
    "        hidden_states = self.mixer(hidden_states, inference_params=inference_params)\n",
    "        return hidden_states, residual\n",
    "\n",
    "    def allocate_inference_cache(self, batch_size, max_seqlen, dtype=None, **kwargs):\n",
    "        return self.mixer.allocate_inference_cache(batch_size, max_seqlen, dtype=dtype, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca989974-7854-4f1b-8ae7-24b495bb54d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "from mamba_ssm.modules.mamba_simple import Mamba\n",
    "\n",
    "def create_block(\n",
    "        d_model,\n",
    "        ssm_cfg=None,\n",
    "        norm_epsilon=1e-5,\n",
    "        rms_norm=False,\n",
    "        residual_in_fp32=False,\n",
    "        fused_add_norm=False,\n",
    "        layer_idx=None,\n",
    "        drop_path=0.,\n",
    "        device=None,\n",
    "        dtype=None,\n",
    "):\n",
    "    if ssm_cfg is None:\n",
    "        ssm_cfg = {}\n",
    "    factory_kwargs = {\"device\": device, \"dtype\": dtype}\n",
    "\n",
    "    mixer_cls = partial(Mamba, layer_idx=layer_idx, **ssm_cfg, **factory_kwargs)\n",
    "    norm_cls = partial(\n",
    "        nn.LayerNorm if not rms_norm else RMSNorm, eps=norm_epsilon, **factory_kwargs\n",
    "    )\n",
    "    block = Block(\n",
    "        d_model,\n",
    "        mixer_cls,\n",
    "        norm_cls=norm_cls,\n",
    "        fused_add_norm=fused_add_norm,\n",
    "        residual_in_fp32=residual_in_fp32,\n",
    "        drop_path=drop_path,\n",
    "    )\n",
    "    block.layer_idx = layer_idx\n",
    "    return block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a43c25b",
   "metadata": {},
   "source": [
    "#### Mamba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "823c4b10-5340-4370-b501-45b1b2c585f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_weights(\n",
    "        module,\n",
    "        n_layer,\n",
    "        initializer_range=0.02,  # Now only used for embedding layer.\n",
    "        rescale_prenorm_residual=True,\n",
    "        n_residuals_per_layer=1,  # Change to 2 if we have MLP\n",
    "):\n",
    "    if isinstance(module, nn.Linear):\n",
    "        if module.bias is not None:\n",
    "            if not getattr(module.bias, \"_no_reinit\", False):\n",
    "                nn.init.zeros_(module.bias)\n",
    "    elif isinstance(module, nn.Embedding):\n",
    "        nn.init.normal_(module.weight, std=initializer_range)\n",
    "\n",
    "    if rescale_prenorm_residual:\n",
    "        # Reinitialize selected weights subject to the OpenAI GPT-2 Paper Scheme:\n",
    "        #   > A modified initialization which accounts for the accumulation on the residual path with model depth. Scale\n",
    "        #   > the weights of residual layers at initialization by a factor of 1/√N where N is the # of residual layers.\n",
    "        #   >   -- GPT-2 :: https://openai.com/blog/better-language-models/\n",
    "        #\n",
    "        # Reference (Megatron-LM): https://github.com/NVIDIA/Megatron-LM/blob/main/megatron/model/gpt_model.py\n",
    "        for name, p in module.named_parameters():\n",
    "            if name in [\"out_proj.weight\", \"fc2.weight\"]:\n",
    "                # Special Scaled Initialization --> There are 2 Layer Norms per Transformer Block\n",
    "                # Following Pytorch init, except scale by 1/sqrt(2 * n_layer)\n",
    "                # We need to reinit p since this code could be called multiple times\n",
    "                # Having just p *= scale would repeatedly scale it down\n",
    "                nn.init.kaiming_uniform_(p, a=math.sqrt(5))\n",
    "                with torch.no_grad():\n",
    "                    p /= math.sqrt(n_residuals_per_layer * n_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23725aaa-b57a-4387-a14f-2fa7d3db01cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class MixerModel(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            d_model: int,\n",
    "            n_layer: int,\n",
    "            ssm_cfg=None,\n",
    "            norm_epsilon: float = 1e-5,\n",
    "            rms_norm: bool = False,\n",
    "            initializer_cfg=None,\n",
    "            fused_add_norm=False,\n",
    "            residual_in_fp32=False,\n",
    "            drop_out_in_block: int = 0.,\n",
    "            drop_path: int = 0.1,\n",
    "            device=None,\n",
    "            dtype=None,\n",
    "    ) -> None:\n",
    "        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n",
    "        super().__init__()\n",
    "        self.residual_in_fp32 = residual_in_fp32\n",
    "\n",
    "        # self.embedding = nn.Embedding(vocab_size, d_model, **factory_kwargs)\n",
    "\n",
    "        # We change the order of residual and layer norm:\n",
    "        # Instead of LN -> Attn / MLP -> Add, we do:\n",
    "        # Add -> LN -> Attn / MLP / Mixer, returning both the residual branch (output of Add) and\n",
    "        # the main branch (output of MLP / Mixer). The model definition is unchanged.\n",
    "        # This is for performance reason: we can fuse add + layer_norm.\n",
    "        self.fused_add_norm = fused_add_norm\n",
    "        if self.fused_add_norm:\n",
    "            if layer_norm_fn is None or rms_norm_fn is None:\n",
    "                raise ImportError(\"Failed to import Triton LayerNorm / RMSNorm kernels\")\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                create_block(\n",
    "                    d_model,\n",
    "                    ssm_cfg=ssm_cfg,\n",
    "                    norm_epsilon=norm_epsilon,\n",
    "                    rms_norm=rms_norm,\n",
    "                    residual_in_fp32=residual_in_fp32,\n",
    "                    fused_add_norm=fused_add_norm,\n",
    "                    layer_idx=i,\n",
    "                    drop_path=drop_path,\n",
    "                    **factory_kwargs,\n",
    "                )\n",
    "                for i in range(n_layer)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.norm_f = (nn.LayerNorm if not rms_norm else RMSNorm)(\n",
    "            d_model, eps=norm_epsilon, **factory_kwargs\n",
    "        )\n",
    "\n",
    "        self.apply(\n",
    "            partial(\n",
    "                _init_weights,\n",
    "                n_layer=n_layer,\n",
    "                **(initializer_cfg if initializer_cfg is not None else {}),\n",
    "            )\n",
    "        )\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.drop_out_in_block = nn.Dropout(drop_out_in_block) if drop_out_in_block > 0. else nn.Identity()\n",
    "\n",
    "    def allocate_inference_cache(self, batch_size, max_seqlen, dtype=None, **kwargs):\n",
    "        return {\n",
    "            i: layer.allocate_inference_cache(batch_size, max_seqlen, dtype=dtype, **kwargs)\n",
    "            for i, layer in enumerate(self.layers)\n",
    "        }\n",
    "\n",
    "    def forward(self, input_ids, pos, inference_params=None):\n",
    "        hidden_states = input_ids  # + pos\n",
    "        residual = None\n",
    "        hidden_states = hidden_states + pos\n",
    "        for layer in self.layers:                   # hidden_states: all 32, 192, 384\n",
    "            hidden_states, residual = layer(\n",
    "                hidden_states, residual, inference_params=inference_params\n",
    "            )\n",
    "            hidden_states = self.drop_out_in_block(hidden_states)\n",
    "        if not self.fused_add_norm:\n",
    "            residual = (hidden_states + residual) if residual is not None else hidden_states\n",
    "            hidden_states = self.norm_f(residual.to(dtype=self.norm_f.weight.dtype))\n",
    "        else:\n",
    "            # Set prenorm=False here since we don't need the residual\n",
    "            fused_add_norm_fn = rms_norm_fn if isinstance(self.norm_f, RMSNorm) else layer_norm_fn\n",
    "            hidden_states = fused_add_norm_fn(\n",
    "                hidden_states,\n",
    "                self.norm_f.weight,\n",
    "                self.norm_f.bias,\n",
    "                eps=self.norm_f.eps,\n",
    "                residual=residual,\n",
    "                prenorm=False,\n",
    "                residual_in_fp32=self.residual_in_fp32,\n",
    "            )\n",
    "\n",
    "        return hidden_states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ce93f7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### FeaturePropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2e08434",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturePropagation(nn.Module):\n",
    "    '''\n",
    "    def __init__(self, input_channel, mlp)\n",
    "    \n",
    "    def forward(self, coords1, coords2, points1, points2)\n",
    "        输入：\n",
    "            某一层输入：coords1  [B, C, N], points1  [B, D, N]\n",
    "            某一层输出：coords2  [B, C, S]，points2  [B, D', S]\n",
    "        返回：\n",
    "            new_points  [B, D'', N]\n",
    "    '''\n",
    "    def __init__(self, input_channel, mlp):\n",
    "        super().__init__()\n",
    "        self.mlp_conv = nn.ModuleList()\n",
    "        self.mlp_bn = nn.ModuleList()\n",
    "        for output_channel in mlp:\n",
    "            self.mlp_conv.append(nn.Conv1d(input_channel, output_channel, 1, bias=False))\n",
    "            self.mlp_bn.append(nn.BatchNorm1d(output_channel))\n",
    "            input_channel = output_channel\n",
    "\n",
    "    def forward(self, coords1, coords2, points1, points2):\n",
    "        '''                                                     第一层          第二层          第三层          第四层\n",
    "            coords1：[B, C, N]   Set Abstraction的输入     eg.  [B, 3, 2048]    [B, 3, 1024]    [B, 3, 256]     [B, 3, 64]\n",
    "            coords2：[B, C, S]   Set Abstraction的输出     eg.  [B, 3, 1024]    [B, 3, 256]     [B, 3, 64]      [B, 3, 16]\n",
    "            points1：[B, D, N]   Set Abstraction的输入     eg.  [B, 9, 2048]    [B, 64, 1024]   [B, 128, 256]   [B, 256, 64]\n",
    "            points2：[B, D', S]  Set Abstraction的输出     eg.  [B, 64, 1024]   [B, 128, 256]   [B, 256, 64]    [B, 512, 16]\n",
    "        '''\n",
    "        # 以第四层为例标明注释\n",
    "        \n",
    "        coords1 = coords1.permute(0, 2, 1)    # [B, 64, 3]\n",
    "        coords2 = coords2.permute(0, 2, 1)    # [B, 16, 3]\n",
    "        \n",
    "        dists, index = three_nn(coords1, coords2)   # [B, 64, 3]  [B, 16, 3]\n",
    "        \n",
    "        dist_recip = 1 / (dists + 1e-8)\n",
    "        norm = torch.sum(dist_recip, -1, keepdim=True)\n",
    "        weight = dist_recip / norm    # [B, 64, 3]\n",
    "        \n",
    "        interpolated_points = three_interpolate(points2, index, weight)\n",
    "\n",
    "        new_points = torch.cat([points1, interpolated_points], dim=1)   # [B, 768, 64]\n",
    "\n",
    "        for conv,bn in zip(self.mlp_conv, self.mlp_bn):\n",
    "            new_points = F.relu(bn(conv(new_points)), inplace=True)\n",
    "        # 最后输出new_points.shape: [B, 256, 64]\n",
    "        \n",
    "        return new_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adb31ff",
   "metadata": {},
   "source": [
    "#### semseg network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b342e5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class semseg_network(nn.Module):\n",
    "    def __init__(self, seg_num=13, k=16, stride=[4, 4, 4, 2]):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv0 = nn.Sequential(\n",
    "                         nn.Conv1d(7, 32, 1),\n",
    "                         nn.BatchNorm1d(32),\n",
    "                         nn.ReLU(inplace=True)\n",
    "                     )\n",
    "        \n",
    "        self.encoder1 = Encoder(32, 64, k, stride[0], 3)\n",
    "        self.encoder2 = Encoder(64, 128, k, stride[1], 6)\n",
    "        self.encoder3 = Encoder(128, 256, k, stride[2], 3)\n",
    "        self.encoder4 = Encoder(256, 512, k, stride[3], 3)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "                       nn.Conv1d(512, 512, 1),\n",
    "                       nn.BatchNorm1d(512),\n",
    "                       nn.ReLU(True)\n",
    "                   )\n",
    "\n",
    "        self.fp4 = FeaturePropagation(768, [256])\n",
    "        self.emb4 = nn.Sequential(\n",
    "            nn.Linear(3, 128),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(128, 256)\n",
    "        )\n",
    "        self.mamba4 = MixerModel(d_model=256, n_layer=2, rms_norm=False, drop_out_in_block=0, drop_path=0.3)\n",
    "        \n",
    "        self.fp3 = FeaturePropagation(384, [128])\n",
    "        self.emb3 = nn.Sequential(\n",
    "            nn.Linear(3, 128),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(128, 128)\n",
    "        )\n",
    "        self.mamba3 = MixerModel(d_model=128, n_layer=2, rms_norm=False, drop_out_in_block=0, drop_path=0.3)\n",
    "        \n",
    "        self.fp2 = FeaturePropagation(192, [64])\n",
    "        self.emb2 = nn.Sequential(\n",
    "            nn.Linear(3, 128),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(128, 64)\n",
    "        )\n",
    "        self.mamba2 = MixerModel(d_model=64, n_layer=2, rms_norm=False, drop_out_in_block=0, drop_path=0.3)\n",
    "\n",
    "\n",
    "        \n",
    "        self.fp1 = FeaturePropagation(96, [32])\n",
    "        self.emb1 = nn.Sequential(\n",
    "            nn.Linear(3, 128),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(128, 32)\n",
    "        )\n",
    "        self.mamba1 = MixerModel(d_model=32, n_layer=2, rms_norm=False, drop_out_in_block=0, drop_path=0.3)\n",
    "        \n",
    "        self.segMLP = nn.Sequential(\n",
    "                          nn.Conv1d(32, 32, 1),\n",
    "                          nn.BatchNorm1d(32),\n",
    "                          nn.ReLU(True),\n",
    "                          nn.Conv1d(32, seg_num, 1)\n",
    "                      )\n",
    "\n",
    "\n",
    "    def forward(self, x, feature):\n",
    "\n",
    "        feature0 = self.conv0(feature)   # [B, 32, N]\n",
    "\n",
    "        feature1, x1, neighbor_index0 = self.encoder1(x, feature0)   # [B, 128, N//4]\n",
    "        feature2, x2, neighbor_index1 = self.encoder2(x1, feature1)   # [B, 256, N//16]\n",
    "        feature3, x3, neighbor_index2 = self.encoder3(x2, feature2)   # [B, 512, N//64]\n",
    "        feature4, x4, neighbor_index3 = self.encoder4(x3, feature3)   # [B, 1024, N//128]\n",
    "\n",
    "        feature4 = self.mlp(feature4)   # [B, 1024, N//512]\n",
    "\n",
    "        feature3 = self.fp4(x3, x4, feature3, feature4)   # [B, 256, N//64]\n",
    "        feature3 = self.mamba4(feature3.permute(0, 2, 1), self.emb4(x3.permute(0, 2, 1))).permute(0, 2, 1).contiguous()\n",
    "        \n",
    "        feature2 = self.fp3(x2, x3, feature2, feature3)   # [B, 128, N//16]\n",
    "        feature2 = self.mamba3(feature2.permute(0, 2, 1), self.emb3(x2.permute(0, 2, 1))).permute(0, 2, 1).contiguous()\n",
    "        \n",
    "        feature1 = self.fp2(x1, x2, feature1, feature2)   # [B, 32, N//4]\n",
    "        feature1 = self.mamba2(feature1.permute(0, 2, 1), self.emb2(x1.permute(0, 2, 1))).permute(0, 2, 1).contiguous()\n",
    "        \n",
    "        feature0 = self.fp1(x, x1, feature0, feature1)   # [B, 32, N]\n",
    "        feature0 = self.mamba1(feature0.permute(0, 2, 1), self.emb1(x.permute(0, 2, 1))).permute(0, 2, 1).contiguous()\n",
    "\n",
    "        # feature0 = torch.cat([feature3.max(-1)[0], feature2.max(-1)[0], feature1.max(-1)[0], feature0.max(-1)[0]], dim=1)\n",
    "\n",
    "        result = self.segMLP(feature0)  # [B, seg_num, N]\n",
    "\n",
    "        return result   # [B, seg_num, N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbb92b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f105f9e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac39c381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc36202",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e65fd2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7704f11b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeec1507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c2e484",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
